{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cuda_device(gpu_num: int):\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_num)\n",
    "set_cuda_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_dir = Path(\"../\")\n",
    "this_dir = root_dir / \"Experiments\"\n",
    "import sys\n",
    "sys.path.insert(0, str(root_dir.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "from src.abstract.abs_nn_theta import NNthHelper\n",
    "from src.nn_theta import ResNETNNthHepler\n",
    "import src.main_helper as main_helper\n",
    "from src.abstract.abs_data import DataHelper\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import utils.common_utils as cu\n",
    "#from plot_utils import plot_beta\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = constants.SHAPENET_NOISE_SMALL\n",
    "dh = main_helper.get_data_helper(dataset_name=dataset_name, logger=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnth_args = {\n",
    "    constants.BATCH_SIZE: 32,\n",
    "}\n",
    "nnth_type = constants.RESNET\n",
    "nnth_name = \"final-baseline-noise-small\"\n",
    "nnth_epochs = 1\n",
    "fit_th = False\n",
    "data_subset = constants.FULL_DATA\n",
    "logger = None\n",
    "nnth_mh = main_helper.fit_theta(nn_theta_type=nnth_type, models_defname=nnth_name,\n",
    "                                    dh = dh, nnth_epochs=nnth_epochs,\n",
    "                                    fit=fit_th, data_subset=data_subset, logger=logger, **nnth_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_nnth = main_helper.fit_theta(nn_theta_type=nnth_type, models_defname=nnth_name,\n",
    "                                    dh = dh, nnth_epochs=nnth_epochs,\n",
    "                                    fit=fit_th, data_subset=data_subset, logger=logger, **nnth_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th100 = main_helper.fit_theta(nn_theta_type=nnth_type, models_defname=\"greedy-final-greedy-noise-small\",\n",
    "                                    dh = dh, nnth_epochs=nnth_epochs,\n",
    "                                    fit=fit_th, data_subset=data_subset, logger=logger, **nnth_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_name = \"final-greedy-noise-small\"\n",
    "greedy_r = main_helper.fit_greedy(dataset_name=dataset_name, nnth=nnth_mh, load_th=True, dh=dh, budget=1000, \n",
    "                                      num_badex=100, R_per_iter=10, models_defname=greedy_name,\n",
    "                                      fit=False, init_theta=False, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predlabels_baseline = baseline_nnth.predict_labels(loader=baseline_nnth._tst_loader)\n",
    "test_predlabels_th100 = th100.predict_labels(loader=baseline_nnth._tst_loader)\n",
    "tst_pred_losses_th100 = th100.get_loaderlosses_perex(loader=th100._tst_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th100.beta_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNPhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_name = None\n",
    "nnphi = main_helper.fit_nnphi(dataset_name=dataset_name, dh=dh, epochs=10, greedy_rec=greedy_r, models_defname=phi_name,\n",
    "                              fit=False, logger=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNPsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_name = None\n",
    "nnpsi = main_helper.fit_nnpsi(dataset_name=dataset_name, dh=dh, psi_tgts=constants.R_WRONG, nn_arch=[32, 8],\n",
    "                                  synR=greedy_r, epochs=10, models_defname=psi_name,\n",
    "                                  fit=False, logger=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ourm Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourm_args_imporved = {\n",
    "    constants.PRETRN_THPSIPSI: {\n",
    "                        constants.THETA: True,\n",
    "                        constants.PHI: False,\n",
    "                        constants.PSI: False\n",
    "            }\n",
    "}\n",
    "\n",
    "ourm_hlpr_improved = main_helper.get_ourm_hlpr(ourm_type=constants.SEQUENTIAL, dh=dh, nnth=nnth_mh,\n",
    "                                        nnphi=nnphi, nnpsi=nnpsi, greedy_r=greedy_r, filter_grps=2500, logger=None, **ourm_args_imporved)\n",
    "ourm_hlpr_improved.load_model_defname(suffix=\"--small-notheta-epoch-40\")\n",
    "\n",
    "test_predlabels_thphi = ourm_hlpr_improved._nnth.predict_labels(loader=baseline_nnth._tst_loader)\n",
    "\n",
    "\n",
    "tst_predbetas_improved = ourm_hlpr_improved._nnphi.predict_beta(loader=ourm_hlpr_improved._nnphi._tst_loader)\n",
    "tst_betas = ourm_hlpr_improved._dh._test._Beta\n",
    "beta_to_idx = {}\n",
    "tst_labels = dh._test._y\n",
    "for i, b in enumerate(tst_betas[0:9]):\n",
    "    beta_to_idx[str(b.tolist())] = i\n",
    "torch.unique(tst_predbetas_improved, dim=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ourm Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourm_args_vannila = {\n",
    "    constants.PRETRN_THPSIPSI: {\n",
    "                        constants.THETA: True,\n",
    "                        constants.PHI: False,\n",
    "                        constants.PSI: False\n",
    "            }\n",
    "}\n",
    "\n",
    "ourm_hlpr_vannila= main_helper.get_ourm_hlpr(ourm_type=constants.SEQUENTIAL, dh=dh, nnth=nnth_mh,\n",
    "                                        nnphi=nnphi, nnpsi=nnpsi, greedy_r=greedy_r, filter_grps=2500, logger=None, **ourm_args_vannila)\n",
    "ourm_hlpr_vannila.load_model_defname(suffix=\"--th_phi-vanilla-shapenet-noise-small\")\n",
    "tst_predbetas_vannila = ourm_hlpr_vannila._nnphi.predict_beta(loader=ourm_hlpr_vannila._nnphi._tst_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score based Triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_score = baseline_nnth.predict_proba(loader=dh._test.get_theta_loader(batch_size=128, shuffle=False))\n",
    "test_max_predprob, _ = torch.max(pred_probs_score,dim=1)\n",
    "ind_order_score_baseline = torch.argsort(test_max_predprob)\n",
    "ind_order_score = ind_order_score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Automation Triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "model_ft = torch.load(\"../baselines/models/models/final-baseline-small-noise-losses.pt\")\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "model_ft.eval()\n",
    "\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for  _,inputs, _ in nnth_mh._tst_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        loss_batch = model_ft(inputs)\n",
    "        losses.append(loss_batch.cpu())\n",
    "\n",
    "losses = torch.cat(losses).view(-1)\n",
    "ind_order_full = torch.argsort(-losses)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain - no training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = th100.predict_proba(loader=th100._tst_loader)\n",
    "pred_prob_max, pred_y = torch.max(pred_prob, dim=1)\n",
    "prior_ybeta_prob = th100.get_conf_ybeta_prior(loader=th100._dh._train_test.get_theta_loader(batch_size=128, shuffle=False))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = torch.zeros(dh._test._num_data)\n",
    "for idx, (y, beta) in enumerate(zip(pred_y, tst_predbetas_improved)):\n",
    "    gains[idx] = prior_ybeta_prob[y.item()][str(beta.tolist())] - pred_prob_max[idx]\n",
    "gains_no_training_improved = torch.argsort(-gains)\n",
    "\n",
    "gains = torch.zeros(dh._test._num_data)\n",
    "for idx, (y, beta) in enumerate(zip(pred_y, tst_predbetas_vannila)):\n",
    "    gains[idx] = prior_ybeta_prob[y.item()][str(beta.tolist())] - pred_prob_max[idx]\n",
    "gains_no_training_vannila = torch.argsort(-gains)\n",
    "\n",
    "gains = torch.zeros(dh._test._num_data)\n",
    "for idx, y in enumerate(pred_y):\n",
    "    gains[idx] = prior_ybeta_prob[y.item()][str([3,1,0])] - pred_prob_max[idx]\n",
    "gains_no_training_const = torch.argsort(-gains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_after_recourse(ind_order, frac, tst_predlabels, pred_betas):\n",
    "    num_samples = int(tst_labels.shape[0]*frac)\n",
    "    rec_crcts = 0\n",
    "    counts = 0\n",
    "    for i in ind_order.tolist()[:num_samples]:\n",
    "        beta_pred = pred_betas[i]\n",
    "        try:\n",
    "            idx = int(i/9)*9 + beta_to_idx[str(beta_pred.tolist())]\n",
    "            label_pred = tst_predlabels[idx]\n",
    "        except:\n",
    "            label_pred = tst_predlabels[i]\n",
    "        if label_pred == tst_labels[i]:\n",
    "            rec_crcts+=1\n",
    "        counts += 1\n",
    "\n",
    "    ind_no_rec = ind_order.tolist()[num_samples:]\n",
    "    rec_crcts += torch.sum(tst_labels[ind_no_rec] == tst_predlabels[ind_no_rec])\n",
    "    counts += len(ind_no_rec)\n",
    "    #print(counts)\n",
    "    acc = rec_crcts/counts\n",
    "    #print(f\"Accuracy with {frac} fraction of recourse is {acc}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_after_constant_recourse(ind_order, frac, tst_predlabels, beta_pred):\n",
    "    num_samples = int(tst_labels.shape[0]*frac)\n",
    "    rec_crcts = 0\n",
    "    counts = 0\n",
    "    for i in ind_order.tolist()[:num_samples]:\n",
    "        #beta_pred = tst_predbetas[i]\n",
    "        # try:\n",
    "        idx = int(i/9)*9 + beta_to_idx[str(beta_pred)]\n",
    "        label_pred = tst_predlabels[idx]\n",
    "        if label_pred == tst_labels[i]:\n",
    "            rec_crcts+=1\n",
    "        counts += 1\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "    ind_no_rec = ind_order.tolist()[num_samples:]\n",
    "    rec_crcts += torch.sum(tst_labels[ind_no_rec] == tst_predlabels[ind_no_rec])\n",
    "    counts += len(ind_no_rec)\n",
    "    #print(counts)\n",
    "    acc = rec_crcts/counts\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi Theirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torchvision import models as tv_models\n",
    "import torch.nn as nn\n",
    "class ResNET(nn.Module):\n",
    "    def __init__(self, out_dim, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.resnet_features =  tv_models.resnet18(pretrained=True)\n",
    "        self.emb_dim = self.resnet_features.fc.in_features\n",
    "        self.resnet_features.fc = nn.Identity()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.emb_dim, self.out_dim[0])\n",
    "        self.fc2 = nn.Linear(self.emb_dim, self.out_dim[1])\n",
    "        self.fc3 = nn.Linear(self.emb_dim, self.out_dim[2])\n",
    "\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward_proba(self, input):\n",
    "        out1,out2,out3 = self.forward(input)\n",
    "        return self.sm(out1),self.sm(out2),self.sm(out3)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out1 = self.resnet_features(input)\n",
    "        out2 = self.resnet_features(input)\n",
    "        out3 = self.resnet_features(input)\n",
    "        #print(out1.shape)\n",
    "        return self.fc1(out1),self.fc2(out2),self.fc3(out3)\n",
    "        \n",
    "    \n",
    "    def forward_labels(self, input):\n",
    "        probs1,probs2,probs3 = self.forward_proba(input)\n",
    "        probs1, labels1 = torch.max(probs1, dim=1)\n",
    "        probs2, labels2 = torch.max(probs2, dim=1)\n",
    "        probs3, labels3 = torch.max(probs3, dim=1)\n",
    "        return labels1,labels2,labels3\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "model_ft = ResNET(out_dim=[6,6,6])\n",
    "model_ft = torch.load(\"../baselines/models/theirs_phi-small.pt\", map_location=\"cuda:0\")\n",
    "\n",
    "model_ft.eval()\n",
    "losses = []\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pred_betas = []\n",
    "unq_beta = dh._test._unq_beta\n",
    "with torch.no_grad():\n",
    "    for _, inputs, _ in nnth_mh._tst_loader:\n",
    "        inputs = inputs.to(device)      \n",
    "        pred_beta_probs = model_ft.forward_proba(inputs)\n",
    "        pred_beta_probs = [entry.cpu()  for entry in pred_beta_probs]\n",
    "\n",
    "        pred_beta = []\n",
    "        for idx in range(len(inputs)):\n",
    "            max_prob = 0\n",
    "            sel_beta = None\n",
    "            for beta_entry in unq_beta:\n",
    "                beta_etry_probs = torch.Tensor([pred_beta_probs[entry][idx][beta_entry[entry]] for entry in range(len(beta_entry))])            \n",
    "                beta_entry_prob = torch.prod(beta_etry_probs)\n",
    "                if beta_entry_prob > max_prob:\n",
    "                    sel_beta = beta_entry\n",
    "                    max_prob = beta_entry_prob\n",
    "            assert sel_beta is not None, \"Why is sel beta none? We should have atleast one positive prob beta\"\n",
    "            pred_beta.append(sel_beta)\n",
    "        pred_betas.append(torch.stack(pred_beta))\n",
    "tst_predbetas_their = torch.cat(pred_betas)\n",
    "\n",
    "\n",
    "#tst_predbetas = beta_pred\n",
    "tst_betas = dh._test._Beta\n",
    "beta_to_idx = {}\n",
    "tst_labels = dh._test._y\n",
    "\n",
    "for i, b in enumerate(tst_betas[0:9]):\n",
    "    beta_to_idx[str(b.tolist())] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = torch.zeros(dh._test._num_data)\n",
    "for idx, (y, beta) in enumerate(zip(pred_y, tst_predbetas_their)):\n",
    "    gains[idx] = prior_ybeta_prob[y.item()][str(beta.tolist())] - pred_prob_max[idx]\n",
    "gains_no_training_their = torch.argsort(-gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final plottintg code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_list = [0.02*i for i in range(51)]\n",
    "acc_list_score = [pred_after_recourse(ind_order_score, i, test_predlabels_baseline, tst_predbetas_improved) for i in frac_list]\n",
    "acc_list_full = [pred_after_recourse(ind_order_full, i, test_predlabels_baseline, tst_predbetas_improved) for i in frac_list]\n",
    "acc_gains_prior_th100_improved =  [pred_after_recourse(gains_no_training_improved, i, test_predlabels_th100, tst_predbetas_improved) for i in frac_list]\n",
    "\n",
    "# acc_gains_prior_th100 =  [pred_after_recourse(gains_no_training, i, test_predlabels_th100, tst_predbetas) for i in frac_list]\n",
    "acc_gains_prior_th100_improved =  [pred_after_recourse(gains_no_training_improved, i, test_predlabels_th100, tst_predbetas_improved) for i in frac_list]\n",
    "acc_list_gain_prior_their_th100 = [pred_after_recourse(gains_no_training_their, i, test_predlabels_th100, tst_predbetas_their) for i in frac_list]\n",
    "acc_list_gain_prior_vannila_th100 = [pred_after_recourse(gains_no_training_vannila, i, test_predlabels_th100,tst_predbetas_vannila) for i in frac_list]\n",
    "acc_list_gains_prior_const_pred = [pred_after_constant_recourse(gains_no_training_const, i, test_predlabels_th100,[3,1,0]) for i in frac_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 25}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc(\"text\", usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(data_x, data_y_all, labels_all, colors_all, markers_all, title, save_name):\n",
    "    plt.clf()\n",
    "    msize = 8\n",
    "    \n",
    "    for data_y, labels, color, marker in zip(data_y_all, labels_all, colors_all, markers_all): \n",
    "    \n",
    "        plt.plot(data_x, data_y, scaley=True, color=color,\n",
    "                 label=labels, marker=marker,# markersize=msize,\n",
    "                 linestyle=\"-\",)\n",
    "\n",
    "    plt.xlabel(\"Fraction of Recourse ($b$)\")\n",
    "    plt.ylabel(\"Recourse Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#     plt.legend(frameon=False, loc='lower right', prop={\"size\":15})\n",
    "    plt.grid(True, alpha=0.5, linewidth=1, color=\"gray\", linestyle=\":\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"./{save_name}.png\", dpi=300, bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = frac_list\n",
    "data_y_all = [acc_list_score, acc_list_full, acc_gains_prior_th100_improved]\n",
    "labels_all = [\"Score based Triage\", \"Full automation Triage\", \"Gains Triage\"]\n",
    "colors_all = [\"b\", \"g\", \"r\"]\n",
    "markers_all = [\".\", \".\", \".\"]\n",
    "title = \"Performance of on Shapenet-Small\"\n",
    "save_name = \"triage_small\"\n",
    "\n",
    "plot_line(data_x, data_y_all, labels_all, colors_all, markers_all, title, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_list_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_list_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_gains_prior_th100_improved])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = frac_list\n",
    "data_y_all = [acc_gains_prior_th100_improved, acc_list_gain_prior_vannila_th100, acc_list_gain_prior_their_th100, acc_list_gains_prior_const_pred]\n",
    "labels_all = [\"Joint Prior\",  \"Joint\", \"Only $\\phi$\", \"Constant prediction\"]\n",
    "colors_all = [\"r\", \"g\", \"b\", \"black\"]\n",
    "markers_all = [\".\", \".\", \".\", \".\"]\n",
    "title = \"Performance of on Shapenet-Small\"\n",
    "save_name = \"phi_small\"\n",
    "\n",
    "plot_line(data_x, data_y_all, labels_all, colors_all, markers_all, title, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_gains_prior_th100_improved])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_list_gain_prior_vannila_th100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_list_gain_prior_their_th100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([entry.item() for entry in acc_list_gains_prior_const_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute class dependent accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_hist(tst_predlabels, pred_betas):\n",
    "    corrects = torch.zeros(dh._test._num_classes)\n",
    "    counts = torch.zeros(dh._test._num_classes)\n",
    "    for i in range(len(tst_predlabels)):\n",
    "        beta_pred = pred_betas[i]\n",
    "        try:\n",
    "            idx = int(i/9)*9 + beta_to_idx[str(beta_pred.tolist())]\n",
    "            label_pred = tst_predlabels[idx]\n",
    "        except:\n",
    "            label_pred = tst_predlabels[i]\n",
    "        if label_pred == tst_labels[i]:\n",
    "            corrects[tst_labels[i]] = corrects[tst_labels[i]] + 1\n",
    "        counts[tst_labels[i]] = counts[tst_labels[i]] + 1\n",
    "\n",
    "    for i in range(dh._test._num_classes):\n",
    "        corrects[i] = corrects[i] / counts[i]\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_predlabels = test_predlabels_th100\n",
    "pred_betas = tst_predbetas_improved\n",
    "\n",
    "corrects = torch.zeros(dh._test._num_classes)\n",
    "counts = torch.zeros(dh._test._num_classes)\n",
    "for i in range(len(tst_predlabels)):\n",
    "    beta_pred = pred_betas[i]\n",
    "    try:\n",
    "        idx = int(i/9)*9 + beta_to_idx[str(beta_pred.tolist())]\n",
    "        label_pred = tst_predlabels[idx]\n",
    "    except:\n",
    "        label_pred = tst_predlabels[i]\n",
    "    if label_pred == tst_labels[i]:\n",
    "        corrects[tst_labels[i]] = corrects[tst_labels[i]] + 1\n",
    "    counts[tst_labels[i]] = counts[tst_labels[i]] + 1\n",
    "\n",
    "for i in range(dh._test._num_classes):\n",
    "    corrects[i] = corrects[i] / counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(corrects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "joint_improved = rec_hist(tst_predlabels=test_predlabels_th100, pred_betas = tst_predbetas_improved).tolist()\n",
    "joint = rec_hist(tst_predlabels=test_predlabels_th100, pred_betas = tst_predbetas_vannila).tolist()\n",
    "constant = rec_hist(tst_predlabels=test_predlabels_th100, pred_betas = torch.tensor([3,1,0]).repeat(7200, 1)).tolist()\n",
    "theirs = rec_hist(tst_predlabels=test_predlabels_th100, pred_betas = tst_predbetas_their).tolist()\n",
    "\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.15\n",
    " \n",
    "# # set\n",
    "# bars = {}\n",
    "# for idx in range(10):\n",
    "#     bars[idx] = [theirs[idx], joint[idx], constant[idx], joint_improved[idx]]\n",
    "\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(10)\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, theirs, color='blue', width=barWidth, edgecolor='white', label='Only $\\phi$')\n",
    "plt.bar(r2, joint, color='green', width=barWidth, edgecolor='white', label='Joint')\n",
    "plt.bar(r3, constant, color='black', width=barWidth, edgecolor='white', label='Constant prediction')\n",
    "plt.bar(r4, joint_improved, color='red', width=barWidth, edgecolor='white', label='Joint Prior')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.ylabel(\"Recourse Accuracy\")\n",
    "plt.xticks([r for r in range(10)], ['Aeroplane', 'Bench', 'Bus', 'Cabinet', 'Chair', 'Display', 'Knife', 'Lamp', 'Speaker', 'Gun'], rotation=75)\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Classwise performance of different ' + '$g_\\phi$' + '\\n on Shapenet-Small')\n",
    "\n",
    "plt.savefig(f\"./histogram_small.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joint_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "076c4ab2a94d6530d87b700124164545302493637a60c32c41a7138ffa64fa6b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
